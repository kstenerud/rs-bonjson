// ABOUTME: Quick benchmark comparing BONJSON vs JSON performance.
// ABOUTME: Covers various data patterns to identify performance characteristics.
// Run with: cargo run --release --example quick_bench

use serde_bonjson::decoder::DecoderConfig;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::time::Instant;

//////////////////////////////////////////////////////////////////////////////
// Test Data Structures
//////////////////////////////////////////////////////////////////////////////

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
struct TestData {
    id: u64,
    name: String,
    email: String,
    scores: Vec<i32>,
    active: bool,
    rating: f64,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
struct NestedData {
    level: u32,
    name: String,
    children: Vec<NestedData>,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
struct FloatHeavy {
    coordinates: Vec<f64>,
    matrix: Vec<Vec<f64>>,
    values: HashMap<String, f64>,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
struct WideObject {
    field_00: i32, field_01: i32, field_02: i32, field_03: i32, field_04: i32,
    field_05: i32, field_06: i32, field_07: i32, field_08: i32, field_09: i32,
    field_10: i32, field_11: i32, field_12: i32, field_13: i32, field_14: i32,
    field_15: i32, field_16: i32, field_17: i32, field_18: i32, field_19: i32,
    name_00: String, name_01: String, name_02: String, name_03: String, name_04: String,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
struct SparseData {
    required_field: String,
    optional_1: Option<i32>,
    optional_2: Option<String>,
    optional_3: Option<Vec<i32>>,
    optional_4: Option<bool>,
    optional_5: Option<f64>,
}

//////////////////////////////////////////////////////////////////////////////
// Data Generators
//////////////////////////////////////////////////////////////////////////////

fn create_test_data(count: usize) -> Vec<TestData> {
    (0..count)
        .map(|i| TestData {
            id: i as u64 * 1000 + 12345,
            name: format!("User Name {}", i),
            email: format!("user{}@example.com", i),
            scores: vec![95, 87, 92, 88, 91, 89, 94, 90, 93, 86],
            active: i % 2 == 0,
            rating: 4.5 + (i as f64 * 0.01),
        })
        .collect()
}

fn create_nested_data(depth: u32, breadth: usize) -> NestedData {
    NestedData {
        level: depth,
        name: format!("Node at depth {}", depth),
        children: if depth == 0 {
            vec![]
        } else {
            (0..breadth)
                .map(|_| create_nested_data(depth - 1, breadth))
                .collect()
        },
    }
}

fn create_long_strings(count: usize, length: usize) -> Vec<String> {
    (0..count)
        .map(|i| {
            let base = format!("String_{:05}_", i);
            // Repeat enough times to exceed length, then truncate
            let repeat_count = (length / base.len()) + 2;
            let long = base.repeat(repeat_count);
            long[..length].to_string()
        })
        .collect()
}

fn create_unicode_strings(count: usize) -> Vec<String> {
    let samples = [
        "Hello, ä¸–ç•Œ! ðŸŒ",
        "ÐŸÑ€Ð¸Ð²ÐµÑ‚ Ð¼Ð¸Ñ€! ðŸš€",
        "ã“ã‚“ã«ã¡ã¯ä¸–ç•Œ ðŸŽŒ",
        "Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù… ðŸŒ™",
        "×©×œ×•× ×¢×•×œ× âœ¡ï¸",
        "Î“ÎµÎ¹Î¬ ÏƒÎ¿Ï… ÎšÏŒÏƒÎ¼Îµ ðŸ›ï¸",
        "ðŸŽ‰ðŸŽŠðŸŽðŸŽˆðŸŽ„ðŸŽƒðŸŽ‡ðŸŽ†",
        "Î•Î»Î»Î·Î½Î¹ÎºÎ¬, æ—¥æœ¬èªž, Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©, ×¢×‘×¨×™×ª",
    ];
    (0..count)
        .map(|i| samples[i % samples.len()].to_string())
        .collect()
}

fn create_float_heavy(size: usize) -> FloatHeavy {
    let mut values = HashMap::new();
    for i in 0..size {
        values.insert(format!("key_{}", i), i as f64 * 0.123456789);
    }
    FloatHeavy {
        coordinates: (0..size).map(|i| i as f64 * 1.5).collect(),
        matrix: (0..10)
            .map(|i| (0..10).map(|j| (i * 10 + j) as f64 * 0.1).collect())
            .collect(),
        values,
    }
}

fn create_wide_objects(count: usize) -> Vec<WideObject> {
    (0..count)
        .map(|i| WideObject {
            field_00: i as i32, field_01: i as i32 + 1, field_02: i as i32 + 2,
            field_03: i as i32 + 3, field_04: i as i32 + 4, field_05: i as i32 + 5,
            field_06: i as i32 + 6, field_07: i as i32 + 7, field_08: i as i32 + 8,
            field_09: i as i32 + 9, field_10: i as i32 + 10, field_11: i as i32 + 11,
            field_12: i as i32 + 12, field_13: i as i32 + 13, field_14: i as i32 + 14,
            field_15: i as i32 + 15, field_16: i as i32 + 16, field_17: i as i32 + 17,
            field_18: i as i32 + 18, field_19: i as i32 + 19,
            name_00: format!("name_{}_0", i), name_01: format!("name_{}_1", i),
            name_02: format!("name_{}_2", i), name_03: format!("name_{}_3", i),
            name_04: format!("name_{}_4", i),
        })
        .collect()
}

fn create_sparse_data(count: usize) -> Vec<SparseData> {
    (0..count)
        .map(|i| SparseData {
            required_field: format!("required_{}", i),
            optional_1: if i % 2 == 0 { Some(i as i32) } else { None },
            optional_2: if i % 3 == 0 { Some(format!("opt_{}", i)) } else { None },
            optional_3: if i % 4 == 0 { Some(vec![1, 2, 3]) } else { None },
            optional_4: if i % 5 == 0 { Some(true) } else { None },
            optional_5: if i % 6 == 0 { Some(i as f64 * 0.5) } else { None },
        })
        .collect()
}

//////////////////////////////////////////////////////////////////////////////
// Benchmark Functions
//////////////////////////////////////////////////////////////////////////////

fn bench_encode<T: Serialize>(name: &str, data: &T, iterations: u32) {
    // Warmup
    for _ in 0..100 {
        let _ = serde_bonjson::to_vec(data);
        let _ = serde_json::to_vec(data);
    }

    // BONJSON encode
    let start = Instant::now();
    for _ in 0..iterations {
        let _ = serde_bonjson::to_vec(data).unwrap();
    }
    let bonjson_time = start.elapsed();

    // JSON encode
    let start = Instant::now();
    for _ in 0..iterations {
        let _ = serde_json::to_vec(data).unwrap();
    }
    let json_time = start.elapsed();

    let bonjson_bytes = serde_bonjson::to_vec(data).unwrap();
    let json_bytes = serde_json::to_vec(data).unwrap();

    let speedup = json_time.as_nanos() as f64 / bonjson_time.as_nanos() as f64;
    let size_diff = (1.0 - bonjson_bytes.len() as f64 / json_bytes.len() as f64) * 100.0;

    println!(
        "{:<40} {:>8.2?} {:>8.2?}  {:>5.2}x  {:>6} {:>6}  {:>+5.1}%",
        name,
        bonjson_time,
        json_time,
        speedup,
        bonjson_bytes.len(),
        json_bytes.len(),
        -size_diff
    );
}

fn bench_decode<T: Serialize + for<'de> Deserialize<'de>>(name: &str, data: &T, iterations: u32) {
    let bonjson_bytes = serde_bonjson::to_vec(data).unwrap();
    let json_bytes = serde_json::to_vec(data).unwrap();

    // Warmup
    for _ in 0..100 {
        let _: T = serde_bonjson::from_slice(&bonjson_bytes).unwrap();
        let _: T = serde_json::from_slice(&json_bytes).unwrap();
    }

    // BONJSON decode
    let start = Instant::now();
    for _ in 0..iterations {
        let _: T = serde_bonjson::from_slice(&bonjson_bytes).unwrap();
    }
    let bonjson_time = start.elapsed();

    // JSON decode
    let start = Instant::now();
    for _ in 0..iterations {
        let _: T = serde_json::from_slice(&json_bytes).unwrap();
    }
    let json_time = start.elapsed();

    let speedup = json_time.as_nanos() as f64 / bonjson_time.as_nanos() as f64;

    println!(
        "{:<40} {:>8.2?} {:>8.2?}  {:>5.2}x",
        name,
        bonjson_time,
        json_time,
        speedup,
    );
}

fn bench_decode_allow_nul<T: Serialize + for<'de> Deserialize<'de>>(name: &str, data: &T, iterations: u32) {
    let bonjson_bytes = serde_bonjson::to_vec(data).unwrap();
    let json_bytes = serde_json::to_vec(data).unwrap();

    // Config with allow_nul = true (skips NUL byte validation)
    let mut config = DecoderConfig::default();
    config.allow_nul = true;

    // Warmup
    for _ in 0..100 {
        let _: T = serde_bonjson::from_slice_with_config(&bonjson_bytes, config.clone()).unwrap();
        let _: T = serde_json::from_slice(&json_bytes).unwrap();
    }

    // BONJSON decode with allow_nul
    let start = Instant::now();
    for _ in 0..iterations {
        let _: T = serde_bonjson::from_slice_with_config(&bonjson_bytes, config.clone()).unwrap();
    }
    let bonjson_time = start.elapsed();

    // JSON decode
    let start = Instant::now();
    for _ in 0..iterations {
        let _: T = serde_json::from_slice(&json_bytes).unwrap();
    }
    let json_time = start.elapsed();

    let speedup = json_time.as_nanos() as f64 / bonjson_time.as_nanos() as f64;

    println!(
        "{:<40} {:>8.2?} {:>8.2?}  {:>5.2}x",
        name,
        bonjson_time,
        json_time,
        speedup,
    );
}

fn print_header(title: &str, show_size: bool) {
    println!("\n{}", "=".repeat(80));
    println!("{}", title);
    println!("{}", "=".repeat(80));
    if show_size {
        println!(
            "{:<40} {:>8} {:>8}  {:>5}   {:>6} {:>6}  {:>6}",
            "Test", "BONJSON", "JSON", "Speed", "BON", "JSON", "Size"
        );
        println!("{}", "-".repeat(80));
    } else {
        println!(
            "{:<40} {:>8} {:>8}  {:>5}",
            "Test", "BONJSON", "JSON", "Speed"
        );
        println!("{}", "-".repeat(56));
    }
}

//////////////////////////////////////////////////////////////////////////////
// Main
//////////////////////////////////////////////////////////////////////////////

fn main() {
    println!("BONJSON vs JSON Performance Comparison");
    println!("(run with: cargo run --release --example quick_bench)\n");

    // ========== ENCODING BENCHMARKS ==========
    print_header("ENCODING BENCHMARKS", true);

    // Basic structured data
    let small = create_test_data(1);
    bench_encode("Small struct (1 object)", &small, 100_000);

    let medium = create_test_data(100);
    bench_encode("Medium struct (100 objects)", &medium, 10_000);

    let large = create_test_data(1000);
    bench_encode("Large struct (1000 objects)", &large, 1_000);

    // Integer arrays
    let small_ints: Vec<i32> = (0..100).collect();
    bench_encode("Small integers (100)", &small_ints, 50_000);

    let large_ints: Vec<i32> = (0..10000).collect();
    bench_encode("Large integers (10000)", &large_ints, 1_000);

    let big_ints: Vec<i64> = (0..1000).map(|i| i64::MAX - i).collect();
    bench_encode("Large i64 values (1000)", &big_ints, 5_000);

    // String tests - short vs long
    let short_strings: Vec<String> = (0..1000).map(|i| format!("s{}", i)).collect();
    bench_encode("Short strings <16 bytes (1000)", &short_strings, 2_000);

    let medium_strings = create_long_strings(1000, 50);
    bench_encode("Medium strings ~50 bytes (1000)", &medium_strings, 1_000);

    let long_strings = create_long_strings(100, 500);
    bench_encode("Long strings ~500 bytes (100)", &long_strings, 2_000);

    let very_long = create_long_strings(10, 10000);
    bench_encode("Very long strings ~10KB (10)", &very_long, 2_000);

    // Unicode strings
    let unicode = create_unicode_strings(1000);
    bench_encode("Unicode strings (1000)", &unicode, 2_000);

    // Nested structures
    let shallow_wide = create_nested_data(2, 10);
    bench_encode("Nested: depth=2, breadth=10", &shallow_wide, 5_000);

    let deep_narrow = create_nested_data(10, 2);
    bench_encode("Nested: depth=10, breadth=2", &deep_narrow, 5_000);

    // Float-heavy data
    let floats = create_float_heavy(100);
    bench_encode("Float-heavy (100 values)", &floats, 2_000);

    // Wide objects (many fields)
    let wide = create_wide_objects(100);
    bench_encode("Wide objects (25 fields each)", &wide, 2_000);

    // Sparse data with optionals
    let sparse = create_sparse_data(1000);
    bench_encode("Sparse data with Options (1000)", &sparse, 1_000);

    // Boolean arrays
    let bools: Vec<bool> = (0..10000).map(|i| i % 2 == 0).collect();
    bench_encode("Boolean array (10000)", &bools, 2_000);

    // Mixed types in map
    let mut mixed: HashMap<String, serde_json::Value> = HashMap::new();
    for i in 0..100 {
        mixed.insert(format!("int_{}", i), serde_json::json!(i));
        mixed.insert(format!("str_{}", i), serde_json::json!(format!("value_{}", i)));
        mixed.insert(format!("bool_{}", i), serde_json::json!(i % 2 == 0));
        mixed.insert(format!("float_{}", i), serde_json::json!(i as f64 * 0.5));
    }
    bench_encode("Mixed HashMap (400 entries)", &mixed, 1_000);

    // ========== DECODING BENCHMARKS ==========
    print_header("DECODING BENCHMARKS", false);

    // Basic structured data
    bench_decode("Small struct (1 object)", &small, 100_000);
    bench_decode("Medium struct (100 objects)", &medium, 10_000);
    bench_decode("Large struct (1000 objects)", &large, 1_000);

    // Integers
    bench_decode("Small integers (100)", &small_ints, 50_000);
    bench_decode("Large integers (10000)", &large_ints, 1_000);
    bench_decode("Large i64 values (1000)", &big_ints, 5_000);

    // Strings
    bench_decode("Short strings <16 bytes (1000)", &short_strings, 2_000);
    bench_decode("Medium strings ~50 bytes (1000)", &medium_strings, 1_000);
    bench_decode("Long strings ~500 bytes (100)", &long_strings, 2_000);
    bench_decode("Very long strings ~10KB (10)", &very_long, 2_000);
    bench_decode("Unicode strings (1000)", &unicode, 2_000);

    // Nested
    bench_decode("Nested: depth=2, breadth=10", &shallow_wide, 5_000);
    bench_decode("Nested: depth=10, breadth=2", &deep_narrow, 5_000);

    // Other types
    bench_decode("Float-heavy (100 values)", &floats, 2_000);
    bench_decode("Wide objects (25 fields each)", &wide, 2_000);
    bench_decode("Sparse data with Options (1000)", &sparse, 1_000);
    bench_decode("Boolean array (10000)", &bools, 2_000);
    bench_decode("Mixed HashMap (400 entries)", &mixed, 1_000);

    // ========== DECODING BENCHMARKS (allow_nul=true) ==========
    print_header("DECODING BENCHMARKS (allow_nul=true, for trusted data)", false);

    // Basic structured data
    bench_decode_allow_nul("Small struct (1 object)", &small, 100_000);
    bench_decode_allow_nul("Medium struct (100 objects)", &medium, 10_000);
    bench_decode_allow_nul("Large struct (1000 objects)", &large, 1_000);

    // Integers
    bench_decode_allow_nul("Small integers (100)", &small_ints, 50_000);
    bench_decode_allow_nul("Large integers (10000)", &large_ints, 1_000);
    bench_decode_allow_nul("Large i64 values (1000)", &big_ints, 5_000);

    // Strings
    bench_decode_allow_nul("Short strings <16 bytes (1000)", &short_strings, 2_000);
    bench_decode_allow_nul("Medium strings ~50 bytes (1000)", &medium_strings, 1_000);
    bench_decode_allow_nul("Long strings ~500 bytes (100)", &long_strings, 2_000);
    bench_decode_allow_nul("Very long strings ~10KB (10)", &very_long, 2_000);
    bench_decode_allow_nul("Unicode strings (1000)", &unicode, 2_000);

    // Nested
    bench_decode_allow_nul("Nested: depth=2, breadth=10", &shallow_wide, 5_000);
    bench_decode_allow_nul("Nested: depth=10, breadth=2", &deep_narrow, 5_000);

    // Other types
    bench_decode_allow_nul("Float-heavy (100 values)", &floats, 2_000);
    bench_decode_allow_nul("Wide objects (25 fields each)", &wide, 2_000);
    bench_decode_allow_nul("Sparse data with Options (1000)", &sparse, 1_000);
    bench_decode_allow_nul("Boolean array (10000)", &bools, 2_000);
    bench_decode_allow_nul("Mixed HashMap (400 entries)", &mixed, 1_000);

    // ========== SUMMARY ==========
    println!("\n{}", "=".repeat(80));
    println!("SUMMARY");
    println!("{}", "=".repeat(80));
    println!("Speed > 1.0x means BONJSON is faster");
    println!("Size shows BONJSON size relative to JSON (negative = smaller)");
    println!();
    println!("BONJSON strengths:");
    println!("  - Encoding: 2-9x faster across all data types");
    println!("  - Decoding: 1.4-8x faster for most workloads");
    println!("  - Compact encoding (25-80% smaller than JSON)");
    println!("  - With allow_nul=true: outperforms JSON even for string-heavy data");
    println!();
    println!("Note on string performance:");
    println!("  By default, BONJSON validates strings for NUL bytes (per spec).");
    println!("  JSON parsers don't do this check, giving them a slight edge on strings.");
    println!("  With `allow_nul: true`, BONJSON beats JSON on strings too (1.3-2.7x).");
    println!();
    println!("Performance tip:");
    println!("  For trusted data, use `from_slice_with_config()` with `allow_nul: true`");
    println!("  to skip NUL byte validation. This significantly speeds up string-heavy");
    println!("  workloads (up to 60% faster for very long strings).");
}
